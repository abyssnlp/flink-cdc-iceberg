apiVersion: flink.apache.org/v1beta1
kind: FlinkDeployment
metadata:
  name: flink-cdc-iceberg
spec:
  image: abyssnlp/flink-cdc-iceberg:0.3
  flinkVersion: v1_20
  flinkConfiguration:
    taskmanager.numberOfTaskSlots: "2"
    s3.access.key: hloGTnOVD3Al5cVlVlvE
    s3.secret.key: 9o2VTSV8r6H6spTEwP5mY8WnWvaOXTsRZSfzfrCb
    s3.endpoint: http://minio.minio.svc.cluster.local:9000
    s3.path.style.access: "true"
    s3.entropy.key: _entropy_
    s3.entropy.length: "4"

    #    execution.checkpointing.interval: "5000"
    execution.checkpointing.externalized-checkpoint-retention: "RETAIN_ON_CANCELLATION"

    # taskmanager memory
    taskmanager.memory.process.size: "10g"
    taskmanager.memory.task.heap.size: "6g"
    taskmanager.memory.managed.size: "2g"
    taskmanager.memory.network.min: "512m"
    taskmanager.memory.network.max: "512m"
    taskmanager.memory.framework.heap.size: "512m"
    taskmanager.memory.framework.off-heap.size: "256m"
    taskmanager.memory.jvm-overhead.min: "512m"

    # Network buffer configuration
    taskmanager.network.memory.buffers-per-channel: "8"
    taskmanager.network.memory.floating-buffers-per-gate: "64"
    taskmanager.network.detailed-metrics: "true"
    metrics.latency.interval: "30000"
    metrics.latency.history-size: "60"

    heartbeat.timeout: "300000"
    heartbeat.interval: "10000"
    pekko.ask.timeout: "600s"

    # JVM parameters
    env.java.opts: >-
      -XX:+UseG1GC 
      -XX:MaxGCPauseMillis=100 
      -XX:+HeapDumpOnOutOfMemoryError 
      -XX:HeapDumpPath=/tmp/heap-dump.hprof
      -XX:G1HeapRegionSize=4m
      -XX:+ExitOnOutOfMemoryError
      -XX:+ParallelRefProcEnabled
      -XX:+DisableExplicitGC


    # restart strategy
    restart-strategy: fixed-delay
    restart-strategy.fixed-delay.attempts: "3"
    restart-strategy.fixed-delay.delay: "30s"

    state.backend: rocksdb
    state.backend.incremental: "true"
    state.backend.rocksdb.memory.managed: "true"
    state.backend.rocksdb.use-bloom-filter: "true"
    state.checkpoints.dir: s3://flink-logs/checkpoints
    state.savepoints.dir: s3://flink-logs/savepoints

    high-availability.type: kubernetes
    high-availability.storageDir: s3://flink-logs/ha

    # logging
    logging.level.root: INFO
    logging.level.org.apache.flink: INFO
    logging.level.org.apache.kafka: INFO
  serviceAccount: flink
  podTemplate:
    spec:
      containers:
        - name: flink-main-container
          env:
            - name: KAFKA_BOOTSTRAP_SERVERS
              valueFrom:
                secretKeyRef:
                  name: flink-cdc-iceberg-secret
                  key: KAFKA_BOOTSTRAP_SERVERS
            - name: KAFKA_GROUP_ID
              valueFrom:
                secretKeyRef:
                  name: flink-cdc-iceberg-secret
                  key: KAFKA_GROUP_ID
            - name: KAFKA_CDC_TOPICS
              valueFrom:
                secretKeyRef:
                  name: flink-cdc-iceberg-secret
                  key: KAFKA_CDC_TOPICS
            - name: S3_ENDPOINT
              valueFrom:
                secretKeyRef:
                  name: flink-cdc-iceberg-secret
                  key: S3_ENDPOINT
            - name: S3_ACCESS_KEY
              valueFrom:
                secretKeyRef:
                  name: flink-cdc-iceberg-secret
                  key: S3_ACCESS_KEY
            - name: S3_SECRET_KEY
              valueFrom:
                secretKeyRef:
                  name: flink-cdc-iceberg-secret
                  key: S3_SECRET_KEY
            - name: ENABLE_BUILT_IN_PLUGINS
              value: "flink-s3-fs-presto-1.20.1.jar"
  jobManager:
    resource:
      memory: "2Gi"
      cpu: 1
  taskManager:
    resource:
      memory: "10Gi"
      cpu: 2
  job:
    jarURI: local:///opt/flink-jobs/flink-cdc-iceberg-1.0.jar
    parallelism: 1
    upgradeMode: savepoint